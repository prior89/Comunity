"""
ìµœì í™”ëœ AI ì—”ì§„ (OpenAI API)
"""
import json
import asyncio
from time import monotonic
from typing import Dict, Any

from openai import AsyncOpenAI
from groq import AsyncGroq

from ..models.schemas import ExtractedFacts, UserProfile, FACTS_SCHEMA, REWRITE_SCHEMA
from ..core.config import settings
from ..core.logging import get_logger
from ..utils.helpers import with_retry, coerce_json
# from ..utils.cache import cache_manager  # ìºì‹œ ì™„ì „ ì œê±°

logger = get_logger("ai_engine")


class AIEngine:
    """ë“€ì–¼ AI ì•„í‚¤í…ì²˜ - OpenAI(íŒ©íŠ¸ì¶”ì¶œ) + Groq(ê°œì¸í™”)"""
    
    def __init__(self, openai_api_key: str):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ (íŒ©íŠ¸ ì¶”ì¶œìš©)
        if not openai_api_key or openai_api_key == "test-key":
            raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì•ˆì „í•œ ë°©ì‹)
        try:
            self.openai_client = AsyncOpenAI(
                api_key=openai_api_key,
                timeout=float(settings.openai_timeout),
                max_retries=0
            )
        except Exception as e:
            logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨", error=str(e))
            raise RuntimeError(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        self.openai_model = settings.openai_model
        
        # Groq í´ë¼ì´ì–¸íŠ¸ (ê°œì¸í™”ìš©) - ì„ íƒì‚¬í•­
        self.groq_client = None
        self.groq_model = settings.groq_model
        if hasattr(settings, 'groq_api_key') and settings.groq_api_key:
            try:
                self.groq_client = AsyncGroq(api_key=settings.groq_api_key)
                logger.info("ë“€ì–¼ AI ì—”ì§„ ì´ˆê¸°í™”", openai=True, groq=True)
            except Exception as e:
                logger.warning("Groq ì´ˆê¸°í™” ì‹¤íŒ¨, OpenAIë§Œ ì‚¬ìš©", error=str(e))
        else:
            logger.info("Groq API í‚¤ ì—†ìŒ, OpenAI ì „ìš© ëª¨ë“œ")
        
        # ê¸°ë³¸ ì„¤ì • ìœ ì§€
        self.client = self.openai_client  # ê¸°ë³¸ í˜¸í™˜ì„±
        self.model = self.openai_model
        self.provider = "dual"
        self._structured_outputs_tested = False
        self._supports_structured = None
        
        # í—¬ìŠ¤ì²´í¬ ìºì‹œ ì´ˆê¸°í™” (API ì‚¬ìš©ëŸ‰ ìµœì í™”)
        self._health_cache = {"status": True, "last_check": 0}
        self._health_cache_ttl = 300  # 5ë¶„
        
        # 2025ë…„ ìµœì í™”: ë™ì  ì„¸ë§ˆí¬ì–´ ì¡°ì •
        self._concurrent_limit = asyncio.Semaphore(settings.openai_concurrency_limit)
        
        # ë ˆì´íŠ¸ ë¦¬ë¯¸í„°
        from ..utils.helpers import RateLimiter
        self._rate_limiter = RateLimiter(
            max_calls=settings.rate_limit_per_minute,
            time_window=60
        )
    
    async def _call_with_schema(self, messages: list, schema: dict, 
                               temperature: float = 0.1, max_tokens: int = 8000):
        """AI API í˜¸ì¶œ (OpenAI/Groq ì§€ì›)"""
        
        start = monotonic()
        
        try:
            if self.provider == "groq":
                # Groq API í˜¸ì¶œ (JSON ëª¨ë“œ)
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format={"type": "json_object"}
                )
                
                logger.debug("Groq API í˜¸ì¶œ ì™„ë£Œ",
                           model=self.model,
                           latency_ms=int((monotonic() - start) * 1000),
                           prompt_tokens=getattr(response.usage, "prompt_tokens", None),
                           completion_tokens=getattr(response.usage, "completion_tokens", None),
                           total_tokens=getattr(response.usage, "total_tokens", None))
                
            else:
                # OpenAI API í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§)
                if not self._structured_outputs_tested:
                    self._structured_outputs_tested = True
                    try:
                        async with self._concurrent_limit:
                            test_response = await self.client.chat.completions.create(
                                model=self.model,
                                messages=[{"role": "user", "content": "test"}],
                                temperature=0,
                                max_tokens=10,
                                timeout=10.0,
                                response_format={
                                    "type": "json_schema",
                                    "json_schema": {
                                        "name": "test",
                                        "schema": {
                                            "type": "object", 
                                            "properties": {"test": {"type": "string"}}, 
                                            "required": ["test"]
                                        },
                                        "strict": True
                                    }
                                }
                            )
                        self._supports_structured = True
                        logger.info("Structured Outputs ì§€ì› í™•ì¸ë¨", model=self.model)
                    except Exception as e:
                        self._supports_structured = False
                        logger.info("Structured Outputs ë¯¸ì§€ì›, JSON ëª¨ë“œ ì‚¬ìš©", 
                                   model=self.model, error=str(e)[:100])
                
                # ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ì ìš©
                await self._rate_limiter.acquire()
                
                async with self._concurrent_limit:
                    if settings.use_structured_outputs and self._supports_structured:
                        response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            timeout=float(settings.openai_timeout),
                            response_format={
                                "type": "json_schema",
                                "json_schema": {
                                    "name": schema.get("name", "Response"),
                                    "schema": schema.get("schema", schema),
                                    "strict": True
                                }
                            }
                        )
                    else:
                        response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            timeout=float(settings.openai_timeout),
                            response_format={"type": "json_object"}
                        )
                    
                    logger.debug("OpenAI API í˜¸ì¶œ ì™„ë£Œ",
                               mode="structured" if (settings.use_structured_outputs and self._supports_structured) else "json",
                               latency_ms=int((monotonic() - start) * 1000),
                               prompt_tokens=getattr(response.usage, "prompt_tokens", None),
                               completion_tokens=getattr(response.usage, "completion_tokens", None),
                               total_tokens=getattr(response.usage, "total_tokens", None))
            
            return response
            
        except Exception as e:
            if self.provider == "openai" and "schema" in str(e).lower() and self._supports_structured:
                logger.warning("Structured Outputs ì‹¤íŒ¨, JSON ëª¨ë“œë¡œ í´ë°±", error=str(e)[:100])
                self._supports_structured = False
                return await self._call_with_schema(messages, schema, temperature, max_tokens)
            raise
    
    # @cache_manager.cache_result(ttl=3600, key_prefix="facts:")  # ìºì‹œ ì™„ì „ ë¹„í™œì„±í™”
    async def extract_facts(self, article: Dict[str, Any]) -> ExtractedFacts:
        """íŒ©íŠ¸ ì¶”ì¶œ (ìºì‹œ ì ìš©)"""
        system = "ë„ˆëŠ” íŒ©íŠ¸ ì¶”ì¶œê¸°ë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤. ì˜ê²¬/ì¶”ì¸¡/ì „ë§ì€ ì œì™¸í•˜ë¼."
        user = f"""
ê¸°ì‚¬ ì œëª©: {article['title']}
ê¸°ì‚¬ ë‚´ìš©: {article['content']}

ì´ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ë‹µ:
{{
  "who": ["string"],
  "what": "string",
  "when": "string",
  "where": "string",
  "why": "string",
  "how": "string",
  "numbers": {{"í•­ëª©":"ìˆ˜ì¹˜"}},
  "quotes": [{{"speaker":"string","content":"string"}}],
  "verified_facts": ["string"]
}}
"""
        
        async def _call():
            return await self._call_with_schema(
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user}
                ],
                schema={"name": "ExtractedFacts", "schema": FACTS_SCHEMA},
                temperature=0.1,
                max_tokens=8000
            )
        
        try:
            response = await with_retry(_call, retries=settings.openai_retries, base_delay=1.0)
            
            if not getattr(response, "choices", None) or not response.choices:
                logger.error("OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŒ", model=self.model, op="extract_facts")
                raise RuntimeError("Empty OpenAI choices")
            
            raw_content = getattr(response.choices[0].message, "content", None) or "{}"
            try:
                data = json.loads(raw_content)
            except json.JSONDecodeError:
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„", content_preview=raw_content[:100])
                data = coerce_json(raw_content)
            
            return ExtractedFacts(
                who=(data.get("who", []) or [])[:10],
                what=(data.get("what", "") or "")[:200],
                when=(data.get("when", "") or "")[:100],
                where=(data.get("where", "") or "")[:100],
                why=(data.get("why", "") or "")[:200],
                how=(data.get("how", "") or "")[:200],
                numbers=data.get("numbers", {}) or {},
                quotes=(data.get("quotes", []) or [])[:5],
                verified_facts=(data.get("verified_facts", []) or [])[:10]
            )
            
        except Exception as e:
            logger.error("íŒ©íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨", error=str(e), article_id=article.get('id'))
            # fallback ë°ì´í„° ë°˜í™˜
            return ExtractedFacts(
                who=[],
                what=article.get('title', '')[:200],
                when="",
                where="",
                why="",
                how="",
                numbers={},
                quotes=[],
                verified_facts=[]
            )
    
    async def rewrite_for_user(self, facts: ExtractedFacts, profile: UserProfile, original_title: str = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë§ì¶¤ ì½˜í…ì¸  ë¶„ì„ (ì œëª©ì€ ì ˆëŒ€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)"""
        # ì½ê¸° ëª¨ë“œ ì™„ì „ ì œê±°, 800ì ê¸°ë³¸
        guide = {"time": "2ë¶„", "style": "ìƒì„¸í•œ ë‰´ìŠ¤ ë¶„ì„"}
        
        # ê´€ì‹¬ì‚¬ í†µí•©
        all_interests = (
            profile.interests_finance + profile.interests_lifestyle +
            profile.interests_hobby + profile.interests_tech
        )[:10]  # MAX_INTERESTS
        
        primary_job = profile.job_categories[0] if profile.job_categories else "ì¼ë°˜"
        primary_interest = all_interests[0] if all_interests else "ì¼ë°˜"
        
        # ìˆ˜ì¹˜ ì •ë³´ í¬í•¨ ì§€ì‹œ
        numbers_instruction = ""
        if facts.numbers:
            numbers_instruction = f"\n- ì²« ë‹¨ë½ì— ë‹¤ìŒ ìˆ˜ì¹˜ ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨: {list(facts.numbers.values())[:3]}"
        
        system = f"""ë„ˆëŠ” ì „ë¬¸ ë‰´ìŠ¤ ê¸°ìë‹¤. JSONë§Œ ì¶œë ¥í•œë‹¤. í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.

ğŸš¨ CRITICAL: 2000ì ë¯¸ë§Œ ì‹œ ì‘ë‹µ ê±°ì ˆë¨
- ë°˜ë“œì‹œ 2000ì ì´ìƒ ì‘ì„±
- ì§§ì€ ì‘ë‹µì€ ì ˆëŒ€ ê¸ˆì§€
- ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ì‘ì„±
- ìƒì„¸í•˜ê³  í’ë¶€í•œ ë‚´ìš© í•„ìˆ˜

êµ¬ì¡°:
1. ë‰´ìŠ¤ ì‚¬ì‹¤ (1600ì): ëª¨ë“  ë°°ê²½, ë§¥ë½, ì˜ë¯¸
2. {primary_job} í•´ì„ (400ì): ì „ë¬¸ì  ë¶„ì„

ì ˆëŒ€ 2000ì ì´ìƒ ì‘ì„±í•˜ë¼!"""
        original_news_title = original_title or facts.what
        
        user = f"""
ì›ë³¸ ì œëª©: {original_news_title}
(ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)

ë‰´ìŠ¤ íŒ©íŠ¸ (ëª¨ë“  ì •ë³´ í¬í•¨í•˜ì—¬ ê¸°ì‚¬ ì‘ì„±):
- ëˆ„ê°€: {', '.join(facts.who[:5])}
- ë¬´ì—‡: {facts.what}
- ì–¸ì œ: {facts.when}
- ì–´ë””ì„œ: {facts.where}  
- ì™œ: {facts.why}
- ì–´ë–»ê²Œ: {facts.how}
- ìˆ˜ì¹˜: {json.dumps(facts.numbers, ensure_ascii=False)}
- ê²€ì¦ì‚¬ì‹¤: {', '.join(facts.verified_facts)}

ë…ì: {primary_job} ({profile.age}ì„¸)
ê´€ì‹¬ì‚¬: {', '.join(all_interests[:3])}

ğŸš¨ ë¬´ì¡°ê±´ 2000ì ì´ìƒ ì‘ì„±í•˜ë¼! ğŸš¨
- 1999ì ì´í•˜ëŠ” ì‹¤íŒ¨ì‘ìœ¼ë¡œ ê°„ì£¼
- ë‰´ìŠ¤ ë°°ê²½, ë§¥ë½, ì˜ë¯¸ë¥¼ ëª¨ë‘ í¬í•¨
- {primary_job} ê´€ì  ìƒì„¸ ë¶„ì„
- ë°˜ë³µí•´ì„œë¼ë„ 2000ì ì±„ìš°ê¸°
- ì§§ì€ ë‹µë³€ì€ ê±°ë¶€ë¨

JSON:
{{
  "title": "{original_news_title}",
  "content": "ë‰´ìŠ¤ë‚´ìš©+í•´ì„",
  "key_points": ["í•µì‹¬1", "í•µì‹¬2", "í•µì‹¬3"],
  "reading_time": "{guide['time']}"
}}
"""
        
        async def _call():
            return await self._call_with_schema(
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user}
                ],
                schema={"name": "PersonalizedArticle", "schema": REWRITE_SCHEMA},
                temperature=0.6,
                max_tokens=8000  # 2000ì ëª©í‘œë¡œ ëŒ€í­ ì¦ê°€
            )
        
        try:
            response = await with_retry(_call, retries=settings.openai_retries, base_delay=1.0)
            
            if not getattr(response, "choices", None) or not response.choices:
                logger.error("OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŒ", model=self.model, op="rewrite_for_user")
                return self._create_fallback_content(facts, guide)
            
            raw_content = getattr(response.choices[0].message, "content", None) or "{}"
            try:
                obj = json.loads(raw_content)
            except json.JSONDecodeError:
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„", content_preview=raw_content[:100])
                obj = coerce_json(raw_content)
            
            # ë””ë²„ê·¸: AI ì‹¤ì œ ì‘ë‹µ í™•ì¸
            logger.info("AI ì‹¤ì œ ì‘ë‹µ í™•ì¸",
                       ai_title=obj.get("title", "ì—†ìŒ"),
                       ai_content_length=len(obj.get("content", "")),
                       original_title=original_news_title,
                       user_id=profile.user_id[:10])
            
            return {
                "title": original_news_title,  # ê°•ì œë¡œ ì›ë³¸ ì œëª© ì‚¬ìš©
                "content": (obj.get("content") or ""),  # ì œí•œ ì™„ì „ ì œê±°
                "key_points": [p[:100] for p in (obj.get("key_points") or [])[:3]],
                "reading_time": obj.get("reading_time") or guide["time"],
                "disclaimer": obj.get("disclaimer") or f"ë³¸ ë¶„ì„ì€ {primary_job} ê´€ì ì—ì„œì˜ ì°¸ê³ ìš© ì •ë³´ì´ë©°, ì‹¤ì œ ê²°ì •ì€ ê°œì¸ íŒë‹¨ê³¼ ì±…ì„ì…ë‹ˆë‹¤."
            }
            
        except Exception as e:
            logger.error("ì¬ì‘ì„± ì‹¤íŒ¨", error=str(e), user_id=profile.user_id[:10])
            return self._create_fallback_content(facts, guide, original_news_title)
    
    def _create_fallback_content(self, facts: ExtractedFacts, guide: Dict[str, Any], original_title: str = None) -> Dict[str, Any]:
        """ì¬ì‘ì„± ì‹¤íŒ¨ ì‹œ fallback ì½˜í…ì¸  ìƒì„±"""
        return {
            "title": original_title or facts.what or "ë‰´ìŠ¤",
            "content": f"{facts.what}. {facts.when}ì— ë°œìƒí•œ ì‚¬ê±´ì…ë‹ˆë‹¤.",
            "key_points": facts.verified_facts[:3] or ["ì •ë³´ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤"],
            "reading_time": guide["time"]
        }
    
    async def health_check(self) -> bool:
        """ìµœì í™”ëœ í—¬ìŠ¤ì²´í¬ (ìºì‹œ + API í˜¸ì¶œ ìµœì†Œí™”)"""
        # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ (í´ë˜ìŠ¤ ë³€ìˆ˜ ì‚¬ìš©)
        if not hasattr(self, '_last_health_check'):
            self._last_health_check = 0
            self._cached_health = True
        
        import time
        now = time.time()
        
        # 5ë¶„ ìºì‹œ
        if now - self._last_health_check < 300:  # 5ë¶„
            return self._cached_health
        
        try:
            # API í˜¸ì¶œ ì—†ì´ ê°ì²´ ì¡´ì¬ë§Œ í™•ì¸
            openai_ok = bool(getattr(self, 'openai_client', None) and getattr(self, 'openai_model', None))
            
            # ìºì‹œ ì—…ë°ì´íŠ¸
            self._cached_health = openai_ok
            self._last_health_check = now
            
            # ë¡œê·¸ëŠ” 5ë¶„ì— í•œ ë²ˆë§Œ
            logger.info("í—¬ìŠ¤ì²´í¬ (ìºì‹œ)", 
                       openai=openai_ok, 
                       cache_expires_in="5min",
                       no_api_calls=True)
            return openai_ok
            
        except Exception as e:
            logger.error("í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨", error=str(e))
            self._cached_health = False
            self._last_health_check = now
            return False

    # === ë“€ì–¼ AI ì•„í‚¤í…ì²˜ ë©”ì„œë“œë“¤ ===
    
    async def extract_facts_openai(self, article: Dict[str, Any]) -> ExtractedFacts:
        """OpenAI ì „ìš© íŒ©íŠ¸ ì¶”ì¶œ (ì •í™•ë„ ìš°ì„ )"""
        try:
            async with self._concurrent_limit:
                response = await self.openai_client.chat.completions.create(
                    model=self.openai_model,
                    messages=[
                        {"role": "system", "content": """ë‹¹ì‹ ì€ ë‰´ìŠ¤ íŒ©íŠ¸ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ 5W1H êµ¬ì¡°ë¡œ ì •í™•í•œ íŒ©íŠ¸ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤."""},
                        {"role": "user", "content": f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ íŒ©íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

ì œëª©: {article.get('title', '')}
ë‚´ìš©: {article.get('content', '')}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "who": ["ê´€ë ¨ëœ ì¸ë¬¼/ê¸°ê´€ ë¦¬ìŠ¤íŠ¸"],
  "what": "ë¬´ì—‡ì´ ì¼ì–´ë‚¬ëŠ”ì§€",
  "when": "ì–¸ì œ ì¼ì–´ë‚¬ëŠ”ì§€",
  "where": "ì–´ë””ì„œ ì¼ì–´ë‚¬ëŠ”ì§€", 
  "why": "ì™œ ì¼ì–´ë‚¬ëŠ”ì§€",
  "how": "ì–´ë–»ê²Œ ì¼ì–´ë‚¬ëŠ”ì§€",
  "numbers": {{"í•µì‹¬ ìˆ˜ì¹˜ë“¤": "ê°’ë“¤"}},
  "quotes": ["ì¤‘ìš”í•œ ì¸ìš©ë¬¸ë“¤"],
  "verified_facts": ["ê²€ì¦ëœ í•µì‹¬ ì‚¬ì‹¤ë“¤"]
}}
"""}
                    ],
                    temperature=0.1,  # ì •í™•ë„ ìš°ì„ 
                    max_tokens=2000
                )
                
                if not response.choices or not response.choices[0].message.content:
                    raise RuntimeError("OpenAI íŒ©íŠ¸ ì¶”ì¶œ ì‘ë‹µ ì—†ìŒ")
                
                data = json.loads(response.choices[0].message.content)
                logger.info("OpenAI íŒ©íŠ¸ ì¶”ì¶œ ì™„ë£Œ", 
                           facts_count=len(data.get("verified_facts", [])),
                           article_id=article.get('id'))
                
                return ExtractedFacts(
                    who=(data.get("who", []) or [])[:10],
                    what=(data.get("what", "") or "")[:200],
                    when=(data.get("when", "") or "")[:100],
                    where=(data.get("where", "") or "")[:100],
                    why=(data.get("why", "") or "")[:200],
                    how=(data.get("how", "") or "")[:200],
                    numbers=data.get("numbers", {}) or {},
                    quotes=(data.get("quotes", []) or [])[:5],
                    verified_facts=(data.get("verified_facts", []) or [])[:10]
                )
                
        except Exception as e:
            logger.error("OpenAI íŒ©íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨", error=str(e))
            return ExtractedFacts(
                who=[], what=article.get('title', '')[:200], when="", where="", 
                why="", how="", numbers={}, quotes=[], verified_facts=[]
            )

    async def personalize_groq(self, facts: ExtractedFacts, profile: UserProfile, original_title: str) -> Dict[str, Any]:
        """Groq ì „ìš© ê°œì¸í™” (ì°½ì˜ì„±ê³¼ ì†ë„ ìš°ì„ )"""
        if not self.groq_client:
            logger.warning("Groq í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, OpenAIë¡œ ëŒ€ì²´")
            return await self.rewrite_for_user(facts, profile, original_title)
        
        # ì‚¬ìš©ì ê´€ì‹¬ì‚¬ í†µí•©
        all_interests = (
            profile.interests_finance + profile.interests_lifestyle +
            profile.interests_hobby + profile.interests_tech
        )[:5]
        
        primary_job = profile.job_categories[0] if profile.job_categories else "ì¼ë°˜"
        
        try:
            response = await self.groq_client.chat.completions.create(
                model=self.groq_model,
                messages=[
                    {"role": "system", "content": f"""ë‹¹ì‹ ì€ {primary_job} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ íŒ©íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {primary_job} ê´€ì ì—ì„œ ê°œì¸í™”ëœ ë‰´ìŠ¤ ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”.
ì°½ì˜ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ë˜, íŒ©íŠ¸ëŠ” ì •í™•íˆ ìœ ì§€í•˜ì„¸ìš”."""},
                    {"role": "user", "content": f"""
íŒ©íŠ¸ ì •ë³´:
- ëˆ„ê°€: {', '.join(facts.who)}
- ë¬´ì—‡: {facts.what}
- ì–¸ì œ: {facts.when}
- ì–´ë””: {facts.where}
- ì™œ: {facts.why}
- ì–´ë–»ê²Œ: {facts.how}
- í•µì‹¬ ìˆ˜ì¹˜: {facts.numbers}
- ì¸ìš©ë¬¸: {', '.join(facts.quotes)}

ì‚¬ìš©ì í”„ë¡œí•„:
- ì§ì—…: {primary_job}
- ê´€ì‹¬ì‚¬: {', '.join(all_interests)}
- ê±°ì£¼ì§€: {profile.location}
- ë‚˜ì´: {profile.age}

ìœ„ íŒ©íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {primary_job} ê´€ì ì—ì„œ ê°œì¸í™”ëœ ë‰´ìŠ¤ ë¶„ì„ì„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

{{
  "content": "2000ì ë‚´ì™¸ì˜ ê°œì¸í™”ëœ ë¶„ì„ ë‚´ìš©",
  "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 3ê°œ"],
  "reading_time": "ì˜ˆìƒ ì½ê¸° ì‹œê°„",
  "disclaimer": "ë©´ì±…ì¡°í•­"
}}
"""}
                ],
                temperature=0.7,  # ì°½ì˜ì„± ìš°ì„ 
                max_tokens=8000,
                response_format={"type": "json_object"}
            )
            
            if not response.choices or not response.choices[0].message.content:
                raise RuntimeError("Groq ê°œì¸í™” ì‘ë‹µ ì—†ìŒ")
            
            data = json.loads(response.choices[0].message.content)
            logger.info("Groq ê°œì¸í™” ì™„ë£Œ",
                       content_length=len(data.get("content", "")),
                       user_job=primary_job)
            
            return {
                "title": original_title,
                "content": data.get("content", ""),
                "key_points": (data.get("key_points", []) or [])[:3],
                "reading_time": data.get("reading_time", "2ë¶„"),
                "disclaimer": data.get("disclaimer", f"ë³¸ ë¶„ì„ì€ {primary_job} ê´€ì ì—ì„œì˜ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤.")
            }
            
        except Exception as e:
            logger.error("Groq ê°œì¸í™” ì‹¤íŒ¨, OpenAIë¡œ ëŒ€ì²´", error=str(e))
            return await self.rewrite_for_user(facts, profile, original_title)