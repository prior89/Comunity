"""
ìµœì í™”ëœ AI ì—”ì§„ (OpenAI API)
"""
import json
import asyncio
from time import monotonic
from typing import Dict, Any

from openai import AsyncOpenAI
from groq import AsyncGroq

from ..models.schemas import ExtractedFacts, UserProfile, FACTS_SCHEMA, REWRITE_SCHEMA
from ..core.config import settings
from ..core.logging import get_logger
from ..utils.helpers import with_retry, coerce_json
# from ..utils.cache import cache_manager  # ìºì‹œ ì™„ì „ ì œê±°

logger = get_logger("ai_engine")


class AIEngine:
    """ìµœì í™”ëœ AI ê¸°ë°˜ ì½˜í…ì¸  ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, api_key: str):
        if settings.ai_provider == "groq":
            if not settings.groq_api_key:
                raise RuntimeError("GROQ_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.client = AsyncGroq(api_key=settings.groq_api_key)
            self.model = settings.groq_model
            self.provider = "groq"
        elif settings.ai_provider == "dual":
            # Dual ëª¨ë“œ: Groqì™€ OpenAI ë‘˜ ë‹¤ ì´ˆê¸°í™”
            if not settings.groq_api_key or not api_key:
                raise RuntimeError("Dual ëª¨ë“œì—ì„œëŠ” GROQ_API_KEYì™€ OPENAI_API_KEYê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
            self.groq_client = AsyncGroq(api_key=settings.groq_api_key)
            self.openai_client = AsyncOpenAI(api_key=api_key, timeout=float(settings.openai_timeout), max_retries=0)
            self.client = self.groq_client  # ê¸°ë³¸ì€ Groq
            self.model = settings.groq_model
            self.provider = "dual"
        else:
            if not api_key or api_key == "test-key":
                raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            self.client = AsyncOpenAI(
                api_key=api_key,
                timeout=float(settings.openai_timeout),
                max_retries=0
            )
            self.model = settings.openai_model
            self.provider = "openai"
        self._structured_outputs_tested = False
        self._supports_structured = None
        
        # 2025ë…„ ìµœì í™”: ë™ì  ì„¸ë§ˆí¬ì–´ ì¡°ì •
        self._concurrent_limit = asyncio.Semaphore(settings.openai_concurrency_limit)
        
        # ë ˆì´íŠ¸ ë¦¬ë¯¸í„°
        from ..utils.helpers import RateLimiter
        self._rate_limiter = RateLimiter(
            max_calls=settings.rate_limit_per_minute,
            time_window=60
        )
    
    async def _call_with_schema(self, messages: list, schema: dict, 
                               temperature: float = 0.1, max_tokens: int = 8000):
        """AI API í˜¸ì¶œ (OpenAI/Groq ì§€ì›)"""
        
        start = monotonic()
        
        try:
            if self.provider == "groq":
                # Groq API í˜¸ì¶œ (JSON ëª¨ë“œ)
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format={"type": "json_object"}
                )
                
                logger.debug("Groq API í˜¸ì¶œ ì™„ë£Œ",
                           model=self.model,
                           latency_ms=int((monotonic() - start) * 1000),
                           prompt_tokens=getattr(response.usage, "prompt_tokens", None),
                           completion_tokens=getattr(response.usage, "completion_tokens", None),
                           total_tokens=getattr(response.usage, "total_tokens", None))
                
            else:
                # OpenAI API í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§)
                if not self._structured_outputs_tested:
                    self._structured_outputs_tested = True
                    try:
                        async with self._concurrent_limit:
                            test_response = await self.client.chat.completions.create(
                                model=self.model,
                                messages=[{"role": "user", "content": "test"}],
                                temperature=0,
                                max_tokens=10,
                                timeout=10.0,
                                response_format={
                                    "type": "json_schema",
                                    "json_schema": {
                                        "name": "test",
                                        "schema": {
                                            "type": "object", 
                                            "properties": {"test": {"type": "string"}}, 
                                            "required": ["test"]
                                        },
                                        "strict": True
                                    }
                                }
                            )
                        self._supports_structured = True
                        logger.info("Structured Outputs ì§€ì› í™•ì¸ë¨", model=self.model)
                    except Exception as e:
                        self._supports_structured = False
                        logger.info("Structured Outputs ë¯¸ì§€ì›, JSON ëª¨ë“œ ì‚¬ìš©", 
                                   model=self.model, error=str(e)[:100])
                
                # ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ì ìš©
                await self._rate_limiter.acquire()
                
                async with self._concurrent_limit:
                    if settings.use_structured_outputs and self._supports_structured:
                        response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            timeout=float(settings.openai_timeout),
                            response_format={
                                "type": "json_schema",
                                "json_schema": {
                                    "name": schema.get("name", "Response"),
                                    "schema": schema.get("schema", schema),
                                    "strict": True
                                }
                            }
                        )
                    else:
                        response = await self.client.chat.completions.create(
                            model=self.model,
                            messages=messages,
                            temperature=temperature,
                            max_tokens=max_tokens,
                            timeout=float(settings.openai_timeout),
                            response_format={"type": "json_object"}
                        )
                    
                    logger.debug("OpenAI API í˜¸ì¶œ ì™„ë£Œ",
                               mode="structured" if (settings.use_structured_outputs and self._supports_structured) else "json",
                               latency_ms=int((monotonic() - start) * 1000),
                               prompt_tokens=getattr(response.usage, "prompt_tokens", None),
                               completion_tokens=getattr(response.usage, "completion_tokens", None),
                               total_tokens=getattr(response.usage, "total_tokens", None))
            
            return response
            
        except Exception as e:
            if self.provider == "openai" and "schema" in str(e).lower() and self._supports_structured:
                logger.warning("Structured Outputs ì‹¤íŒ¨, JSON ëª¨ë“œë¡œ í´ë°±", error=str(e)[:100])
                self._supports_structured = False
                return await self._call_with_schema(messages, schema, temperature, max_tokens)
            raise
    
    # @cache_manager.cache_result(ttl=3600, key_prefix="facts:")  # ìºì‹œ ì™„ì „ ë¹„í™œì„±í™”
    async def extract_facts(self, article: Dict[str, Any]) -> ExtractedFacts:
        """íŒ©íŠ¸ ì¶”ì¶œ (ìºì‹œ ì ìš©)"""
        system = "ë„ˆëŠ” íŒ©íŠ¸ ì¶”ì¶œê¸°ë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤. ì˜ê²¬/ì¶”ì¸¡/ì „ë§ì€ ì œì™¸í•˜ë¼."
        user = f"""
ê¸°ì‚¬ ì œëª©: {article['title']}
ê¸°ì‚¬ ë‚´ìš©: {article['content']}

ì´ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ë‹µ:
{{
  "who": ["string"],
  "what": "string",
  "when": "string",
  "where": "string",
  "why": "string",
  "how": "string",
  "numbers": {{"í•­ëª©":"ìˆ˜ì¹˜"}},
  "quotes": [{{"speaker":"string","content":"string"}}],
  "verified_facts": ["string"]
}}
"""
        
        async def _call():
            return await self._call_with_schema(
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user}
                ],
                schema={"name": "ExtractedFacts", "schema": FACTS_SCHEMA},
                temperature=0.1,
                max_tokens=8000
            )
        
        try:
            response = await with_retry(_call, retries=settings.openai_retries, base_delay=1.0)
            
            if not getattr(response, "choices", None) or not response.choices:
                logger.error("OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŒ", model=self.model, op="extract_facts")
                raise RuntimeError("Empty OpenAI choices")
            
            raw_content = getattr(response.choices[0].message, "content", None) or "{}"
            try:
                data = json.loads(raw_content)
            except json.JSONDecodeError:
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„", content_preview=raw_content[:100])
                data = coerce_json(raw_content)
            
            return ExtractedFacts(
                who=(data.get("who", []) or [])[:10],
                what=(data.get("what", "") or "")[:200],
                when=(data.get("when", "") or "")[:100],
                where=(data.get("where", "") or "")[:100],
                why=(data.get("why", "") or "")[:200],
                how=(data.get("how", "") or "")[:200],
                numbers=data.get("numbers", {}) or {},
                quotes=(data.get("quotes", []) or [])[:5],
                verified_facts=(data.get("verified_facts", []) or [])[:10]
            )
            
        except Exception as e:
            logger.error("íŒ©íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨", error=str(e), article_id=article.get('id'))
            # fallback ë°ì´í„° ë°˜í™˜
            return ExtractedFacts(
                who=[],
                what=article.get('title', '')[:200],
                when="",
                where="",
                why="",
                how="",
                numbers={},
                quotes=[],
                verified_facts=[]
            )
    
    async def rewrite_for_user(self, facts: ExtractedFacts, profile: UserProfile, original_title: str = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë§ì¶¤ ì½˜í…ì¸  ë¶„ì„ (ì œëª©ì€ ì ˆëŒ€ ë³€ê²½í•˜ì§€ ì•ŠìŒ)"""
        # ì½ê¸° ëª¨ë“œ ì™„ì „ ì œê±°, 800ì ê¸°ë³¸
        guide = {"time": "2ë¶„", "style": "ìƒì„¸í•œ ë‰´ìŠ¤ ë¶„ì„"}
        
        # ê´€ì‹¬ì‚¬ í†µí•©
        all_interests = (
            profile.interests_finance + profile.interests_lifestyle +
            profile.interests_hobby + profile.interests_tech
        )[:10]  # MAX_INTERESTS
        
        primary_job = profile.job_categories[0] if profile.job_categories else "ì¼ë°˜"
        primary_interest = all_interests[0] if all_interests else "ì¼ë°˜"
        
        # ìˆ˜ì¹˜ ì •ë³´ í¬í•¨ ì§€ì‹œ
        numbers_instruction = ""
        if facts.numbers:
            numbers_instruction = f"\n- ì²« ë‹¨ë½ì— ë‹¤ìŒ ìˆ˜ì¹˜ ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨: {list(facts.numbers.values())[:3]}"
        
        system = f"""ë„ˆëŠ” ì „ë¬¸ ë‰´ìŠ¤ ê¸°ìë‹¤. JSONë§Œ ì¶œë ¥í•œë‹¤. í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.

ğŸš¨ CRITICAL: 2000ì ë¯¸ë§Œ ì‹œ ì‘ë‹µ ê±°ì ˆë¨
- ë°˜ë“œì‹œ 2000ì ì´ìƒ ì‘ì„±
- ì§§ì€ ì‘ë‹µì€ ì ˆëŒ€ ê¸ˆì§€
- ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ì‹œ ì‘ì„±
- ìƒì„¸í•˜ê³  í’ë¶€í•œ ë‚´ìš© í•„ìˆ˜

êµ¬ì¡°:
1. ë‰´ìŠ¤ ì‚¬ì‹¤ (1600ì): ëª¨ë“  ë°°ê²½, ë§¥ë½, ì˜ë¯¸
2. {primary_job} í•´ì„ (400ì): ì „ë¬¸ì  ë¶„ì„

ì ˆëŒ€ 2000ì ì´ìƒ ì‘ì„±í•˜ë¼!"""
        original_news_title = original_title or facts.what
        
        user = f"""
ì›ë³¸ ì œëª©: {original_news_title}
(ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)

ë‰´ìŠ¤ íŒ©íŠ¸ (ëª¨ë“  ì •ë³´ í¬í•¨í•˜ì—¬ ê¸°ì‚¬ ì‘ì„±):
- ëˆ„ê°€: {', '.join(facts.who[:5])}
- ë¬´ì—‡: {facts.what}
- ì–¸ì œ: {facts.when}
- ì–´ë””ì„œ: {facts.where}  
- ì™œ: {facts.why}
- ì–´ë–»ê²Œ: {facts.how}
- ìˆ˜ì¹˜: {json.dumps(facts.numbers, ensure_ascii=False)}
- ê²€ì¦ì‚¬ì‹¤: {', '.join(facts.verified_facts)}

ë…ì: {primary_job} ({profile.age}ì„¸)
ê´€ì‹¬ì‚¬: {', '.join(all_interests[:3])}

ğŸš¨ ë¬´ì¡°ê±´ 2000ì ì´ìƒ ì‘ì„±í•˜ë¼! ğŸš¨
- 1999ì ì´í•˜ëŠ” ì‹¤íŒ¨ì‘ìœ¼ë¡œ ê°„ì£¼
- ë‰´ìŠ¤ ë°°ê²½, ë§¥ë½, ì˜ë¯¸ë¥¼ ëª¨ë‘ í¬í•¨
- {primary_job} ê´€ì  ìƒì„¸ ë¶„ì„
- ë°˜ë³µí•´ì„œë¼ë„ 2000ì ì±„ìš°ê¸°
- ì§§ì€ ë‹µë³€ì€ ê±°ë¶€ë¨

JSON:
{{
  "title": "{original_news_title}",
  "content": "ë‰´ìŠ¤ë‚´ìš©+í•´ì„",
  "key_points": ["í•µì‹¬1", "í•µì‹¬2", "í•µì‹¬3"],
  "reading_time": "{guide['time']}"
}}
"""
        
        async def _call():
            # dual ëª¨ë“œì—ì„œëŠ” Groq ë¨¼ì € ì‹œë„, ì‹¤íŒ¨í•˜ë©´ OpenAI
            if self.provider == "dual":
                try:
                    # Groq ì‹œë„
                    self.client = self.groq_client
                    self.model = settings.groq_model
                    logger.info("ê°œì¸í™” ì‹œë„: Groq ìš°ì„ ")
                    return await self._call_with_schema(
                        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                        schema={"name": "PersonalizedArticle", "schema": REWRITE_SCHEMA},
                        temperature=0.6,
                        max_tokens=8000
                    )
                except Exception as e:
                    # OpenAIë¡œ fallback
                    logger.warning(f"Groq ì‹¤íŒ¨, OpenAI ëŒ€ì²´: {e}")
                    self.client = self.openai_client
                    self.model = settings.openai_model
                    return await self._call_with_schema(
                        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                        schema={"name": "PersonalizedArticle", "schema": REWRITE_SCHEMA},
                        temperature=0.6,
                        max_tokens=8000
                    )
            else:
                # ë‹¨ì¼ ëª¨ë“œ
                return await self._call_with_schema(
                    messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                    schema={"name": "PersonalizedArticle", "schema": REWRITE_SCHEMA},
                    temperature=0.6,
                    max_tokens=8000
                )
        
        try:
            response = await with_retry(_call, retries=settings.openai_retries, base_delay=1.0)
            
            if not getattr(response, "choices", None) or not response.choices:
                logger.error("OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŒ", model=self.model, op="rewrite_for_user")
                return self._create_fallback_content(facts, guide)
            
            raw_content = getattr(response.choices[0].message, "content", None) or "{}"
            try:
                obj = json.loads(raw_content)
            except json.JSONDecodeError:
                logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„", content_preview=raw_content[:100])
                obj = coerce_json(raw_content)
            
            # ë””ë²„ê·¸: AI ì‹¤ì œ ì‘ë‹µ í™•ì¸
            logger.info("AI ì‹¤ì œ ì‘ë‹µ í™•ì¸",
                       ai_title=obj.get("title", "ì—†ìŒ"),
                       ai_content_length=len(obj.get("content", "")),
                       original_title=original_news_title,
                       user_id=profile.user_id[:10])
            
            # ìƒˆë¡œìš´ í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
            from .groq_fallback import run_personalize
            
            # íŒ©íŠ¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            facts_text = f"""
ì œëª©: {original_news_title}
ë‚´ìš©: {facts.what}
ì¸ë¬¼: {', '.join(facts.who[:3])}
ì‹œì : {facts.when}
ë°°ê²½: {facts.why}
"""
            
            # í”„ë¡œí•„ ì •ë³´ë¥¼ dictë¡œ ë³€í™˜
            profile_dict = {
                "role": primary_job,
                "interests": all_interests,
                "reading_mode": "insight"
            }
            
            # í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ê°œì¸í™” ì‹¤í–‰
            result = await run_personalize(facts_text, profile_dict)
            
            return {
                "title": original_news_title,
                "content": result["personalized_article"],
                "personalized_article": result["personalized_article"],
                "key_points": [f"{primary_job} ê´€ì  ë¶„ì„", "AI ê¸°ë°˜ ë§ì¶¤í˜• ì¬êµ¬ì„±", "ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì²˜ë¦¬"],
                "reading_time": guide["time"],
                "disclaimer": f"ë³¸ ë¶„ì„ì€ {primary_job} ê´€ì ì—ì„œì˜ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤.",
                "provider": result["provider"],
                "model": result.get("model", "unknown")
            }
            
        except Exception as e:
            logger.error("ì¬ì‘ì„± ì‹¤íŒ¨", error=str(e), user_id=profile.user_id[:10])
            return self._create_fallback_content(facts, guide, original_news_title)
    
    def _create_fallback_content(self, facts: ExtractedFacts, guide: Dict[str, Any], original_title: str = None) -> Dict[str, Any]:
        """ì¬ì‘ì„± ì‹¤íŒ¨ ì‹œ fallback ì½˜í…ì¸  ìƒì„±"""
        return {
            "title": original_title or facts.what or "ë‰´ìŠ¤",
            "content": f"{facts.what}. {facts.when}ì— ë°œìƒí•œ ì‚¬ê±´ì…ë‹ˆë‹¤.",
            "key_points": facts.verified_facts[:3] or ["ì •ë³´ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤"],
            "reading_time": guide["time"]
        }
    
    async def health_check(self) -> bool:
        """AI ì—”ì§„ ìƒíƒœ í™•ì¸"""
        try:
            async with self._concurrent_limit:
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "ping"}],
                    temperature=0,
                    max_tokens=5,
                    timeout=10.0
                )
                return bool(response.choices)
        except Exception as e:
            logger.error("AI ì—”ì§„ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨", error=str(e))
            return False